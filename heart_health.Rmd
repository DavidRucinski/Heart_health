---
title: "Heart Health"
author: "David Rucinski"
date: "July 15, 2019"

output:
  html_document:
    theme: cerulean
    highlight: espresso
    toc: true
    toc_float: false
    toc_depth: 4
    df_print: kable
    code_folding: hide
---


```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)
```

## **Preparations**
```{r packages, message = FALSE, warning=FALSE}
library(data.table)
library(ggplot2)
library(dplyr)
library(RColorBrewer) # for some color
library(plyr) # revalue()
#library(MASS) # models
```


## **Analysis**


### Data
```{r}

heart <- fread("heart.csv", header = TRUE)
heart.test <- fread("heart.csv", header = TRUE)
#str(heart)
#head(health)

#corrplot::corrplot(cor(heart), method = "number", type = "upper", tl.col="black", order="hclust", tl.srt=45, col=brewer.pal(n=8, name="PuOr"))

```

### Preprocessing
```{r colnames clarity of variables}

##### For a Little bit of clarity of variables
list_names <- c("Age" , "Gender", "ChestPain", "RestingBloodPressure", "Cholestrol", "FastingBloodSugar", "RestingECG", "MaxHeartRateAchivied", "ExerciseIndusedAngina", "Oldpeak", "Slope", "MajorVessels", "Thalassemia", "Target")

colnames(heart) <- list_names

```

### Principal Components Analysis: Male & Female


#### Log of few variables (PCA is sensitive)
```{r}
log.list <- c("Age","RestingBloodPressure", "Cholestrol",  "MaxHeartRateAchivied")

ln.heart <- copy(heart)

ln.heart[ , (log.list) := lapply(.SD, log), .SDcols = log.list]

head(ln.heart)
# head(heart) I needed to change ln.heart to copy(DT), it was referencing it as a pointer would in C
# thus my original DT heart was being modified as well.
```


#### Male Hearts
```{r}
MaleHeart <- subset(ln.heart, Gender == 1)
FemaleHeart <- subset(ln.heart, Gender == 0)


MaleHeart <- MaleHeart[,-2]
#ln.Male <- log(MaleHeart)

FemaleHeart <- FemaleHeart[,-2]
#ln.Female <- log(FemaleHeart)

#PCA on the covariance matrix of ln transformed data on male hearts


pca.MaleHeart <- prcomp(MaleHeart)

#pca.MaleHeart

summary(pca.MaleHeart)


biplot(pca.MaleHeart, scale = 0) #Furthest variables account for more (keep???)
```




##### Obtain the scores on the first principal component
```{r}
scores.PC1 <- as.matrix(MaleHeart) %*% pca.MaleHeart$rotation[,1]
scores.PC2 <- as.matrix(MaleHeart) %*% pca.MaleHeart$rotation[,2]
scores.PC3 <- as.matrix(MaleHeart) %*% pca.MaleHeart$rotation[,3]
```


### Male scree plot
```{r, fig.width = 15, fig.height = 12}
plot(pca.MaleHeart$sdev, xlab = "Component number", ylab = "Eigenvalue = component variance", type = 'l', main = "Male Hearts: Scree Diagram for PCA on Covariance Matrix")

#pca.MaleHeart$rotation
```



```{r, fig.width = 15, fig.height = 12}
# c(min(scores.PC1),max(scores.PC1))
# c(min(scores.PC2),max(scores.PC2))


plot(scores.PC1,scores.PC2, main = "Male Hearts: PCA on S: 
     Scatterplot of PC1 on PC2 Scores", xlim = c( -1.521836, 4.837029), ylim = c(-2.88651,3.67108))




PCs1on2 <- cbind(scores.PC1, scores.PC2)
require(stats)

# chull(PCs1on2) used for points

 plot(PCs1on2, cex = 0.75, pch = 16, main = "Male Hearts: PCA on S: 
      Scatterplot of PC1 Scores vs PC2 Scores, with Convex Hull", xlim = c( -1.521836, 4.837029), ylim = c(-2.88651,3.67108),xlab = "PC1 Score", ylab = "PC2 Score")
 hpts <- chull(PCs1on2)
 hpts <- c(hpts,hpts[1])
 lines(PCs1on2[hpts,])


```



### Female Hearts
```{r}
#PCA on the covariance matrix of ln transformed data on female hearts


pca.FemaleHeart <- prcomp(FemaleHeart)

# pca.FemaleHeart

summary(pca.FemaleHeart)



```




##### Obtain the scores on the first principal component
```{r}
scores.PC1 <- as.matrix(FemaleHeart) %*% pca.FemaleHeart$rotation[,1]
scores.PC2 <- as.matrix(FemaleHeart) %*% pca.FemaleHeart$rotation[,2]
scores.PC3 <- as.matrix(FemaleHeart) %*% pca.FemaleHeart$rotation[,3]
```


### Female scree plot
```{r, fig.width = 15, fig.height = 12}
plot(pca.FemaleHeart$sdev, xlab = "Component number", ylab = "Eigenvalue = component variance", type = 'l', main = "Female Hearts: Scree Diagram for PCA on Covariance Matrix")

# pca.FemaleHeart$rotation
```



```{r, fig.width = 15, fig.height = 12}
# c(min(scores.PC1),max(scores.PC1))
# c(min(scores.PC2),max(scores.PC2))


plot(scores.PC1,scores.PC2, main = "Female Hearts: PCA on S: 
     Scatterplot of PC1 on PC2 Scores", xlim = c( -6.225462, 1.432780), ylim = c(-0.203207,3.863399))




PCs1on2 <- cbind(scores.PC1, scores.PC2)

# chull(PCs1on2)


 plot(PCs1on2, cex = 0.75, pch = 16, main = "Female Hearts: PCA on S: 
      Scatterplot of PC1 Scores vs PC2 Scores, with Convex Hull", xlim = c( -6.225462, 1.432780), ylim = c(-0.203207,3.863399),xlab = "PC1 Score", ylab = "PC2 Score")
 hpts <- chull(PCs1on2)
 hpts <- c(hpts,hpts[1])
 lines(PCs1on2[hpts,])

 # Can I split the plot healthy/disease ?

 
```












>>> HERE <<<

## Factors
```{r as factors for plots}

heart$Gender <-  as.factor(heart$Gender)
heart$ChestPain <- as.factor(heart$ChestPain)
heart$ExerciseIndusedAngina <- as.factor(heart$ExerciseIndusedAngina)
heart$Thalassemia <- as.factor(heart$Thalassemia)
heart$Target <- as.factor(heart$Target)
```


```{r}
levels(heart$ChestPain)

heart <- transform(heart,
          ChestPain=revalue(ChestPain,c("0"="Typical Angina", "1"="Atypical Angina", "2"="Non-Anginal", "3"="Asymptomatic")))

heart <- transform(heart,
          Gender=revalue(Gender, c("0"="Female", "1"="Male")))


heart <- transform(heart,
          Target=revalue(Target, c("0"="Healthy Heart", "1"="Heart Disease")))

summary(heart$Age)
# Min age is 29, max 77
# ("Young (29-45)","Middle Aged (45-65)","Old Age (>65)")
# Maybe change grouping?

```

>>>Comment above what it all means, show the PC rotation for the linear combination of variables




###Plots
```{r}
library(ggthemes)
posn_d <- position_dodge(width = 0.4)


heart %>%
  ggplot( aes(x = factor(ChestPain), fill = factor(Target))) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Chest Pain", y = "Count",title = "Heart Health", subtitle = "By type of chest pain", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "goldenrod1", "Heart Disease" = "darkviolet")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 


heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(Target)) ) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Sex",title = "Heart Health", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_color_fivethirtyeight() + 
  theme_fivethirtyeight() +
  theme(legend.title = element_blank()) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "brown1", "Heart Disease" = "forestgreen"))


heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(ChestPain) )) +
  geom_bar(position = "dodge" ,alpha = 0.6) +
  labs(x = "Sex", y = "Count",title = "Type of Chest Pain", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=position_dodge(width = 0.9), vjust = -0.3) +
  theme_stata() + scale_fill_stata() +
  theme(legend.title = element_blank()) 
#Add Titles


heart[, .N, by = .(Age, Target, Gender)] %>%
  ggplot( aes(x = Age, y = N) ) +
  geom_col( fill = "dodgerblue") +
  facet_grid(Gender ~ Target, scales = "free") +
  labs( y = "Count",title = "Age Distribution", subtitle = "By heart health and sex", caption = "Heart Disease UCI from Kaggle") +
  theme_stata() + scale_fill_stata()
  


```





```{r univariate histograms, eval=FALSE, include=FALSE}
 library(purrr)
 
 heart %>%
  keep(is.numeric) %>%    
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
   theme_grey()

```
###Corrplot
```{r, fig.width=12, fig.height=10, echo=FALSE}

corr.heart <- cor(na.omit(heart.test))

corrplot::corrplot(corr.heart,type="upper", method="color", insig = "blank", order="hclust", diag=FALSE, addCoef.col = "black", tl.col="black", tl.srt=27)

```

###Models
```{r}
names(heart)

model.0 <- glm(Target ~ 1, data = heart, family ="binomial")
model.1 <- glm(Target ~ . -Slope, data = heart, family = "binomial")

step(model.0 , scope = formula(model.1), direction="forward", k = 2)

# model.heart <- train(heart, heart$Target, preProcess = c("medianImpute", "center","scale"))

model.heart <- glm(formula = Target ~ ChestPain + Thalassemia + MajorVessels + 
    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
    Cholestrol + RestingBloodPressure + RestingECG, family = "binomial", 
    data = heart)

summary(model.heart)


1-pchisq(1420.24-701.69, 1024-1010) #-> this is plausible with data given those variables
# Reject null hypo: Constant vs added variables models are not the same


car::vif(model.heart)


# Cross-validation of model, checking accuracy
library(caret)
library(glmnet)


# This bad boy is needed
levels(heart$Target) <- make.names(levels(factor(heart$Target)))


model.fold <- train(
  Target ~ ChestPain + Thalassemia + MajorVessels + 
    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
    Cholestrol + RestingBloodPressure + RestingECG, 
  heart,
  method="glm", family="binomial",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
)

model.fold


model.fold2 <- train(
  Target ~ ., 
  heart,
  method="glm", family="binomial",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
)

model.fold2

# More accurate with model selected via stepwise function

# Random-Forest modeling


tune.grid <- data.frame(
  .mtry = c(2, 3, 7),
  .splitrule = "variance",
  .min.node.size = 5
)


  #  model.forest <- train(
  #    Target ~.,
  #    tuneGrid = tune.grid,
  #    data = heart,
  #    method = "ranger",
  #    trControl = trainControl(
  #      method = "cv", 
  #      number = 5, 
  #      verboseIter = TRUE
  #    )
  # )
  #  
  #  model.forest
  #  
  #  plot(model.forest)


# Glmnet modeling

myControl <- trainControl(
  method = "cv", 
  number = 10,
  summaryFunction = twoClassSummary,              #twoClassSummary for logistic
  classProbs = TRUE, # <- Super important!
  verboseIter = TRUE
)

set.seed(13)
 model.glmnet <- train(
   Target ~ ., 
   heart, 
   method = "glmnet", 
   trControl = myControl
 )
 
 plot(model.glmnet)
# doesn't look useful here with defaultSummary



model.glmnet2 <- train(
  Target ~., 
  heart,
  tuneGrid = expand.grid(
  alpha = 0:1,
  lambda = seq(0.0001, 1, length = 20)
),
  method = "glmnet",
  trControl = myControl
)


plot(model.glmnet2)
max(model.glmnet2[["results"]][["ROC"]])




split <- round(nrow(heart)*.60)
train.set <- heart[1:split,]
test.set  <- heart[(split+1):nrow(heart),]


model_rf <- train(
  Target ~ ., 
  train.set,
  metric = "ROC",
  method = "ranger", 
  trControl = myControl
)

plot(model_rf)
```


```{r testing ML}
library(broom)
library(rsample)
library(Metrics)
library(ranger)
library(purrr)
library(dplyr)

set.seed(1337)

# Prepare the initial split object
data_split <- initial_split(heart, prop = 0.60)

# Extract the training dataframe
training_data <- training(data_split)

# Extract the testing dataframe
testing_data <- testing(data_split)



set.seed(1337)
cv_split <- vfold_cv(training_data, v = 5)

cv_data <- cv_split %>% 
  mutate(train = map(splits, ~training(.x)),validate = map(splits, ~testing(.x)))

# Extract the train dataframe for each split
# Extract the validate dataframe for each split
  

cv_models_lr <- cv_data %>% 
  mutate(model = map(train, ~glm(formula = Target~., data = .x, family = "binomial")))


# Examine the first model and validate 
model <- cv_models_lr$model[[1]]
validate <- cv_models_lr$validate[[1]]


# Prepare binary vector of actual Heart Disease values in validate
validate_actual <- validate$Target == "Heart.Disease"

# Predict the probabilities for the observations in validate
validate_prob <- predict(model, validate, type = "response")


# Prepare binary vector of predicted Heart Disease values for validate
validate_predicted <- validate_prob > 0.5





# Compare the actual & predicted performance visually using a table
table(validate_actual, validate_predicted)

Metrics::accuracy(validate_actual, validate_predicted)
Metrics::precision(validate_actual, validate_predicted)
Metrics::recall(validate_actual, validate_predicted)



cv_prep_lr <- cv_models_lr %>% 
  mutate(validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
         validate_predicted = map2(.x = model, .y = validate, 
                                   ~predict(.x, .y, type = "response") > 0.5)
         )


# Validate recall for each cross validation fold
cv_perf_recall <- cv_prep_lr %>% 
  mutate(validate_recall = map2_dbl(validate_actual, validate_predicted, 
                                    ~recall(actual = .x, predicted = .y)))


cv_perf_recall$validate_recall
mean(cv_perf_recall$validate_recall)



# Comparing to Random Forest model


 cv_tune <- cv_data %>%  
   expand_grid(mtry = 2:13) # mtry range 1:# of features
 
 #NOTE: crossing() has been updated, expand_grid() now replaces it.

cv_models_rf <- cv_tune %>% 
  mutate(model = map2(train, mtry, ~ranger(formula = Target~., 
                                           data = .x, mtry = .y, 
                                           num.trees = 700, seed = 1337)))



cv_prep_rf <- cv_models_rf %>% 
  mutate( validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
           validate_predicted = map2(.x = model, .y = validate, 
                                     ~predict(.x, .y, type = "response")$predictions == "Heart.Disease")
         )


cv_perf_recall <- cv_prep_rf %>% 
  mutate(recall = map2_dbl(.x = validate_actual, .y = validate_predicted, ~recall(actual = .x, predicted = .y)))


">>>>>>>NOT WORKING, summarize() is out of wack. Does not show combinations anymore<<<<<<<"
# Mean recall for each mtry used  
cv_perf_recall %>% 
  group_by(mtry) %>% 
  summarise(mean_recall = mean(recall))



# Tuning mtry
cv_eval_tune <- cv_prep_rf %>% 
 mutate(validate_mae = map2_dbl(.x = validate_actual, .y = validate_predicted, ~mae(actual = .x, predicted = .y)))


# Mean validate MAE for each fold and mtry combination
cv_eval_tune %>% 
  group_by(mtry) %>%
  summarise(mean_validate_mae = mean(validate_mae))

#########
#   select(mtry, validate_mae) 
# 
# class(test)
# as.tbl(test) %>%
#   group_by(mtry) %>%
#    summarise(mean_validate_mae = mean(validate_mae))
# 
# 
# 
# cv_eval_tune %>%
#   group_map(mean(validate_mae), keep = FALSE)
#   group_map(.tbl, .f, ..., keep = FALSE)
#   
#########


# Building best model using all the training data

best_model <- ranger(formula = Target~., data = training_data , mtry = 4, num.trees = 700, seed = 1337)


test_actual <- testing_data$Target == "Heart.Disease"
test_predicted <- predict(best_model, testing_data, type = "response")$predictions == "Heart.Disease"

# sum(as.numeric(predictions(best_model, testing_data, type = "response"))-1)/769 > 0.5
# 51.88% 



table(test_actual,test_predicted)
Metrics::accuracy(test_actual,test_predicted)
Metrics::precision(test_actual,test_predicted)
Metrics::recall(test_actual,test_predicted)


mae(test_actual, test_predicted)


```





