---
title: "Example"
author: "David Rucinski"
date: "November 7, 2019"
output:
  html_document:
    theme: cerulean
    highlight: espresso
    toc: true
    toc_float: false
    toc_depth: 4
    df_print: kable
    code_folding: hide
---


```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)

#   R version 3.6.1 “Action of the Toes” 
```

##Packages
```{r packages, message = FALSE, warning=FALSE}
library(data.table)  #fread()
library(ggplot2)
library(dplyr)       #The usual
library(caret)       #train()
library(rsample)     #initial_split() vfold_cv()
library(purrr)       #map()
library(Metrics)     #recall() mae()
library(ranger)      #ranger()
library(glmnet)      #glmnet()
library(broom)       #map()
library(ggthemes)    #theme_
```

##Data
###Importing
```{r Reading in Data}
heart <- fread("heart.csv", header = TRUE)
heart.c <- fread("heart.csv", header = TRUE)

glimpse(heart)
```


###Cleaning
```{r colnames clarity of variables}

##### For a Little bit of clarity of variables
list_names <- c("Age" , "Gender", "ChestPain", "RestingBloodPressure", "Cholestrol", "FastingBloodSugar", "RestingECG", "MaxHeartRateAchivied", "ExerciseIndusedAngina", "Oldpeak", "Slope", "MajorVessels", "Thalassemia", "Target")

colnames(heart) <- list_names

```

```{r as factors for plots}

heart$Gender <-  as.factor(heart$Gender)
heart$ChestPain <- as.factor(heart$ChestPain)
heart$ExerciseIndusedAngina <- as.factor(heart$ExerciseIndusedAngina)
heart$Thalassemia <- as.factor(heart$Thalassemia)
heart$Target <- as.factor(heart$Target)
```

```{r renaming factors}
# levels(heart$ChestPain)

heart <- transform(heart,
          ChestPain=plyr::revalue(ChestPain,c("0"="Typical Angina", "1"="Atypical Angina", "2"="Non-Anginal", "3"="Asymptomatic")))

heart <- transform(heart,
          Gender=plyr::revalue(Gender, c("0"="Female", "1"="Male")))


heart <- transform(heart,
          Target=plyr::revalue(Target, c("0"="Healthy Heart", "1"="Heart Disease")))

glimpse(heart)
```



##Visuals
###Correlation Plot
```{r, fig.width=12, fig.height=10, echo=FALSE}

corr.heart <- cor(na.omit(heart.c))

corrplot::corrplot(corr.heart,type="upper", method="color", insig = "blank", order="hclust", diag=FALSE, addCoef.col = "black", tl.col="black", tl.srt=27)

rm(heart.c)
```

###Heart Health Graphs in Different Styles
*Minimal & custom colour*
```{r, fig.width = 12, fig.height = 8}
posn_d <- position_dodge(width = 0.4)


heart %>%
  ggplot( aes(x = factor(ChestPain), fill = factor(Target))) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Chest Pain", y = "Count",title = "Heart Health", subtitle = "By type of chest pain", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "goldenrod1", "Heart Disease" = "mediumorchid1")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 
```

*Fivethirtyeight & custom colour*
```{r, fig.width = 12, fig.height = 8}
heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(Target)) ) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Sex",title = "Heart Health", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_color_fivethirtyeight() + 
  theme_fivethirtyeight() +
  theme(legend.title = element_blank()) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "brown1", "Heart Disease" = "forestgreen"))
```

*Stata theme*
```{r, fig.width = 12, fig.height = 8}
heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(ChestPain) )) +
  geom_bar(position = "dodge" ,alpha = 0.6) +
  labs(x = "Sex", y = "Count",title = "Type of Chest Pain", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=position_dodge(width = 0.9), vjust = -0.3) +
  theme_stata() + scale_fill_stata() +
  theme(legend.title = element_blank()) 
```

*Stata blue*
```{r, fig.width = 12, fig.height = 8}
heart[, .N, by = .(Age, Target, Gender)] %>%
  ggplot( aes(x = Age, y = N) ) +
  geom_col( fill = "dodgerblue") +
  facet_grid(Gender ~ Target, scales = "free") +
  labs( y = "Count",title = "Age Distribution", subtitle = "By heart health and sex", caption = "Heart Disease UCI from Kaggle") +
  theme_stata()
  


```


##Modeling
###Training Data
```{r Training data}
levels(heart$Target) <- make.names(levels(factor(heart$Target)))

set.seed(1337)

# Prepare the initial split object
data_split <- initial_split(heart, prop = 0.65)

# Extract the training dataframe
training_data <- training(data_split)

# Extract the testing dataframe
testing_data <- testing(data_split)



set.seed(1337)
cv_split <- vfold_cv(training_data, v = 5)

cv_data <- cv_split %>% 
  mutate(train = map(splits, ~training(.x)),validate = map(splits, ~testing(.x)))


########################################################
myControl <- trainControl(
  method = "cv", 
  number = 10,
  summaryFunction = twoClassSummary,              #twoClassSummary for logistic
  classProbs = TRUE, # <- Super important!
  verboseIter = TRUE
)
########################################################

```

###Random Forest - Cross-Validated Models
```{r Random Forest}

 cv_tune <- cv_data %>%  
   expand_grid(mtry = 2:13) # mtry range 1:# of features
 
 #NOTE: crossing() has been updated, expand_grid() now replaces it.

cv_models_rf <- cv_tune %>% 
  mutate(model = map2(train, mtry, ~ranger(formula = Target~., 
                                           data = .x, mtry = .y, 
                                           num.trees = 2000, seed = 1337)))



cv_prep_rf <- cv_models_rf %>% 
  mutate( validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
           validate_predicted = map2(.x = model, .y = validate, 
                                     ~predict(.x, .y, type = "response")$predictions == "Heart.Disease")
         )



# Recall on Random Forest models at different levels of mtry
cv_perf_recall <- cv_prep_rf %>% 
  mutate(recall = map2_dbl(.x = validate_actual, .y = validate_predicted, ~recall(actual = .x, predicted = .y)))

temp <- cv_perf_recall %>%
  select(mtry, recall)
j = matrix(nrow = 12, ncol = 2)

for(i in 2:13){
  j[i-1,] = i
  j[i-1,2] = temp %>%
            filter(mtry == i) %>%
             summarize(mean_recall = mean(recall)) %>%
             as.numeric()
}

colnames(j) <-  c("mtry","mean_recall")
knitr::kable(as.data.frame(j))



# Tuning mtry
cv_eval_tune <- cv_prep_rf %>% 
 mutate(validate_mae = map2_dbl(.x = validate_actual, .y = validate_predicted, ~mae(actual = .x, predicted = .y)))


#################################################################
# Mean validate MAE for each fold and mtry combination
# cv_eval_tune %>% 
#   group_by(mtry) %>%
#   summarise(mean_validate_mae = mean(validate_mae))
      #Not working it did before

# cv_eval_tune %>%
#   select(mtry, validate_mae) %>%
#   group_nest(mtry) %>%
#   unnest()
      #Kind of gets there
#################################################################





temp <- cv_eval_tune %>%
  select(mtry, validate_mae)
k = matrix(nrow = 12, ncol = 2)

for(i in 2:13){
  k[i-1,] = i
  k[i-1,2] = temp %>%
            filter(mtry == i) %>%
             summarize(mean_validate_mae = mean(validate_mae)) %>%
             as.numeric()
}

colnames(k) <-  c("mtry","mean_validate_mae")
knitr::kable(as.data.frame(k))

```

**Comment HERE** Recall and validate mae for mtry hyper-parameter tuning.


####RF model
```{r, fig.width=12, fig.height=10,}
split <- round(nrow(heart)*.60)
train.set <- heart[1:split,]
test.set  <- heart[(split+1):nrow(heart),]


model_rf <- train(
  Target ~ ., 
  train.set,
  metric = "ROC",
  method = "ranger", 
  trControl = myControl
)

plot(model_rf)
knitr::kable(model_rf$results)

model_rf$bestTune
```

**Comment HERE** gini/(extra trees), ROC plot, best tune


###Logistic Regression - Cross-Validated Models
```{r Logistic Regression}

cv_models_lr <- cv_data %>% 
  mutate(model = map(train, ~glm(formula = Target~., data = .x, family = "binomial")))


# Examine the first model and validate 
model <- cv_models_lr$model[[1]]
validate <- cv_models_lr$validate[[1]]


# Prepare binary vector of actual Heart Disease values in validate
validate_actual <- validate$Target == "Heart.Disease"

# Predict the probabilities for the observations in validate
validate_prob <- predict(model, validate, type = "response")


# Prepare binary vector of predicted Heart Disease values for validate
validate_predicted <- validate_prob > 0.5
# Compare the actual & predicted performance visually using a table
knitr::kable(table(validate_actual, validate_predicted))
```

**Comment ??**



**Accuracy**
```{r}
Metrics::accuracy(validate_actual, validate_predicted)
```

**Precision**
```{r}
Metrics::precision(validate_actual, validate_predicted)
```

**Recall**
```{r}
Metrics::recall(validate_actual, validate_predicted)
```


```{r}

cv_prep_lr <- cv_models_lr %>% 
  mutate(validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
         validate_predicted = map2(.x = model, .y = validate, 
                                   ~predict(.x, .y, type = "response") > 0.5)
         )


# Validate recall for each cross validation fold
cv_perf_recall <- cv_prep_lr %>% 
  mutate(validate_recall = map2_dbl(validate_actual, validate_predicted, 
                                    ~recall(actual = .x, predicted = .y)))


cv_perf_recall$validate_recall
mean(cv_perf_recall$validate_recall)
```

**Comment HERE**



####Lr model and Glm model
```{r, fig.width=12, fig.height=10,}

# Variable selection via stepwise
model.fold <- train(
  Target ~ ChestPain + Thalassemia + MajorVessels + 
    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
    Cholestrol + RestingBloodPressure + RestingECG, 
  heart,
  method="glm", family="binomial",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
)

model.fold
```

**Comment HERE** results of fold



```{r}
# All Variables for logistic
model.fold2 <- train(
  Target ~ ., 
  heart,
  method="glm", family="binomial",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
)

model.fold2
```

**Comment HERE** results of fold



```{r}
# Glmnet modeling

set.seed(13)
 model.glmnet <- train(
   Target ~ ., 
   heart, 
   method = "glmnet", 
   trControl = myControl
 )
 
 plot(model.glmnet)
```

**Comment HERE** on plot and regularization parameter 
 
 
 
```{r}
# Custom tuning
tune.grid <- data.frame(
  .mtry = 2:length(heart),
  .splitrule = "variance",
  .min.node.size = 5
)

# Lasso or Ridge
model.glmnet2 <- train(
  Target ~., 
  heart,
  tuneGrid = expand.grid(
  alpha = 0:1,
  lambda = seq(0.0001, 1, length = 20)
),
  method = "glmnet",
  trControl = myControl
)


plot(model.glmnet2)
max(model.glmnet2[["results"]][["ROC"]])
```

**Comment HERE** Lasso vs Ridge regression, max ROC & ROC explain(?)



###Stepwise Selection - Logistic Regression
```{r}
model.0 <- glm(Target ~ 1, data = heart, family ="binomial")
model.1 <- glm(Target ~ . -Slope, data = heart, family = "binomial")

# step(model.0 , scope = formula(model.1), direction="forward", k = 2)
# formula = Target ~ ChestPain + Thalassemia + MajorVessels + 
#    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
#    Cholestrol + RestingBloodPressure + RestingECG

model.heart <- glm(formula = Target ~ ChestPain + Thalassemia + MajorVessels + 
    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
    Cholestrol + RestingBloodPressure + RestingECG, family = "binomial", 
    data = heart)

summary(model.heart)

```


###Final Model(?)
```{r Best Model}

best_model <- ranger(formula = Target~., data = training_data , mtry = 12, num.trees = 2000, seed = 1337)

test_actual <- testing_data$Target == "Heart.Disease"
test_predicted <- predict(best_model, testing_data, type = "response")$predictions == "Heart.Disease"

# sum(as.numeric(predictions(best_model, testing_data, type = "response"))-1)/769 > 0.5
# 51.88% 



knitr::kable(table(test_actual,test_predicted))

```

**Accuracy**
```{r}
Metrics::accuracy(test_actual,test_predicted)
```

**Precision**
```{r}
Metrics::precision(test_actual,test_predicted)
```

**Recall**
```{r}
Metrics::recall(test_actual,test_predicted)
```

**Mean Absolute Error**
```{r}
mae(test_actual, test_predicted)
```







