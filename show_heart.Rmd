---
title: "Example"
author: "David Rucinski"
date: "November 7, 2019"
output:
  html_document:
    theme: cerulean
    highlight: espresso
    toc: true
    toc_float: false
    toc_depth: 4
    df_print: kable
    code_folding: hide
---


```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)

#   R version 3.6.1 “Action of the Toes” 
```

##Packages
```{r packages, message = FALSE, warning=FALSE}
library(data.table)  #fread()
library(ggplot2)
library(dplyr)       #The usual
library(caret)       #train()
library(rsample)     #initial_split() vfold_cv()
library(purrr)       #map()
library(Metrics)     #recall() mae()
library(ranger)      #ranger()
library(glmnet)      #glmnet()
library(broom)       #map()
library(ggthemes)    #theme_
```

##Data
###Importing
```{r Reading in Data}
heart <- fread("heart.csv", header = TRUE)
heart.c <- fread("heart.csv", header = TRUE)

glimpse(heart)
```


###Cleaning
```{r colnames clarity of variables}

##### For a Little bit of clarity of variables
list_names <- c("Age" , "Gender", "ChestPain", "RestingBloodPressure", "Cholestrol", "FastingBloodSugar", "RestingECG", "MaxHeartRateAchivied", "ExerciseIndusedAngina", "Oldpeak", "Slope", "MajorVessels", "Thalassemia", "Target")

colnames(heart) <- list_names

```

```{r as factors for plots}

heart$Gender <-  as.factor(heart$Gender)
heart$ChestPain <- as.factor(heart$ChestPain)
heart$ExerciseIndusedAngina <- as.factor(heart$ExerciseIndusedAngina)
heart$Thalassemia <- as.factor(heart$Thalassemia)
heart$Target <- as.factor(heart$Target)
```

```{r renaming factors}
# levels(heart$ChestPain)

heart <- transform(heart,
          ChestPain=plyr::revalue(ChestPain,c("0"="Typical Angina", "1"="Atypical Angina", "2"="Non-Anginal", "3"="Asymptomatic")))

heart <- transform(heart,
          Gender=plyr::revalue(Gender, c("0"="Female", "1"="Male")))


heart <- transform(heart,
          Target=plyr::revalue(Target, c("0"="Healthy Heart", "1"="Heart Disease")))

glimpse(heart)
```



##Visuals
###Correlation Plot
```{r, fig.width=12, fig.height=10, echo=FALSE}

corr.heart <- cor(na.omit(heart.c))

corrplot::corrplot(corr.heart,type="upper", method="color", insig = "blank", order="hclust", diag=FALSE, addCoef.col = "black", tl.col="black", tl.srt=27)


```

###Heart Health Graphs in Different Styles
*Minimal & custom colour*
```{r, fig.width = 12, fig.height = 8}
posn_d <- position_dodge(width = 0.4)


heart %>%
  ggplot( aes(x = factor(ChestPain), fill = factor(Target))) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Chest Pain", y = "Count",title = "Heart Health", subtitle = "By type of chest pain", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "goldenrod1", "Heart Disease" = "mediumorchid1")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 
```

*Fivethirtyeight & custom colour*
```{r, fig.width = 12, fig.height = 8}
heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(Target)) ) +
  geom_bar(position = posn_d ,alpha = 0.8) +
  labs(x = "Sex",title = "Heart Health", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=posn_d, vjust = -0.3) +
  scale_color_fivethirtyeight() + 
  theme_fivethirtyeight() +
  theme(legend.title = element_blank()) +
  scale_fill_manual("legend", values = c("Healthy Heart" = "brown1", "Heart Disease" = "forestgreen"))
```

*Stata theme*
```{r, fig.width = 12, fig.height = 8}
heart %>%
  ggplot( aes(x = factor(Gender), fill = factor(ChestPain) )) +
  geom_bar(position = "dodge" ,alpha = 0.6) +
  labs(x = "Sex", y = "Count",title = "Type of Chest Pain", subtitle = "By sex", caption = "Heart Disease UCI from Kaggle") +
  geom_text(aes(label=..count..),stat="count",position=position_dodge(width = 0.9), vjust = -0.3) +
  theme_stata() + scale_fill_stata() +
  theme(legend.title = element_blank()) 
```

*Stata blue*
```{r, fig.width = 12, fig.height = 8}
heart[, .N, by = .(Age, Target, Gender)] %>%
  ggplot( aes(x = Age, y = N) ) +
  geom_col( fill = "dodgerblue") +
  facet_grid(Gender ~ Target, scales = "free") +
  labs( y = "Count",title = "Age Distribution", subtitle = "By heart health and sex", caption = "Heart Disease UCI from Kaggle") +
  theme_stata()
  


```


##Modeling
*Problem: Classification*
###Training Data
```{r Training data}
levels(heart$Target) <- make.names(levels(factor(heart$Target)))

set.seed(1337)

# Prepare the initial split object
data_split <- initial_split(heart, prop = 0.65)

# Extract the training dataframe
training_data <- training(data_split)

# Extract the testing dataframe
testing_data <- testing(data_split)



set.seed(1337)
cv_split <- vfold_cv(training_data, v = 5)

cv_data <- cv_split %>% 
  mutate(train = map(splits, ~training(.x)),validate = map(splits, ~testing(.x)))


########################################################
myControl <- trainControl(
  method = "cv", 
  number = 10,
  summaryFunction = twoClassSummary,              #twoClassSummary for logistic
  classProbs = TRUE,                              #Classifcation probabilities
  verboseIter = TRUE
)
########################################################

```

###Random Forest - Cross-Validated Models
```{r Random Forest}

 cv_tune <- cv_data %>%  
   expand_grid(mtry = 2:13) # mtry range 1:# of features
 
 #NOTE: crossing() has been updated, expand_grid() now replaces it.

cv_models_rf <- cv_tune %>% 
  mutate(model = map2(train, mtry, ~ranger(formula = Target~., 
                                           data = .x, mtry = .y, 
                                           num.trees = 2000, seed = 1337)))



cv_prep_rf <- cv_models_rf %>% 
  mutate( validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
           validate_predicted = map2(.x = model, .y = validate, 
                                     ~predict(.x, .y, type = "response")$predictions == "Heart.Disease")
         )



# Recall on Random Forest models at different levels of mtry
cv_perf_recall <- cv_prep_rf %>% 
  mutate(recall = map2_dbl(.x = validate_actual, .y = validate_predicted, ~recall(actual = .x, predicted = .y)))

temp <- cv_perf_recall %>%
  select(mtry, recall)
j = matrix(nrow = 12, ncol = 2)

for(i in 2:13){
  j[i-1,] = i
  j[i-1,2] = temp %>%
            filter(mtry == i) %>%
             summarize(mean_recall = mean(recall)) %>%
             as.numeric()
}

colnames(j) <-  c("mtry","mean_recall")
knitr::kable(as.data.frame(j))



# Tuning mtry
cv_eval_tune <- cv_prep_rf %>% 
 mutate(validate_mae = map2_dbl(.x = validate_actual, .y = validate_predicted, ~mae(actual = .x, predicted = .y)))


#################################################################
# Mean validate MAE for each fold and mtry combination
# cv_eval_tune %>% 
#   group_by(mtry) %>%
#   summarise(mean_validate_mae = mean(validate_mae))
      #Not working it did before

# cv_eval_tune %>%
#   select(mtry, validate_mae) %>%
#   group_nest(mtry) %>%
#   unnest()
      #Kind of gets there
#################################################################





temp <- cv_eval_tune %>%
  select(mtry, validate_mae)
k = matrix(nrow = 12, ncol = 2)

for(i in 2:13){
  k[i-1,] = i
  k[i-1,2] = temp %>%
            filter(mtry == i) %>%
             summarize(mean_validate_mae = mean(validate_mae)) %>%
             as.numeric()
}

colnames(k) <-  c("mtry","mean_validate_mae")
knitr::kable(as.data.frame(k))

```

The Mean Absolute Error (MAE) measures how much on average the predicted values differ from actual values, taking the mean of the MAE over different folds the hyperparameter mtry is best at 12. 

On average the true positive rate (Sensitivity/Recall) seems to increase as mtry increases, in general. These predictive models performance quite well.

####Model Results on Test Data
**Mean Absolute Error**
```{r best Random Forest model}
best_model <- ranger(formula = Target~., data = training_data , mtry = 12, num.trees = 2000, seed = 1337)

test_actual <- testing_data$Target == "Heart.Disease"
test_predicted <- predict(best_model, testing_data, type = "response")$predictions == "Heart.Disease"

mae(test_actual, test_predicted)
```


**Accuracy**
Measures how well the model predicted both TRUE and FALSE classes.
```{r}
Metrics::accuracy(test_actual,test_predicted)
```

**Precision**
Calculates how often the model is correct at the TRUE class."
```{r}
Metrics::precision(test_actual,test_predicted)
```




```{r eval=FALSE, fig.height=10, fig.width=12, include=FALSE}
split <- round(nrow(heart)*.60)
train.set <- heart[1:split,]
test.set  <- heart[(split+1):nrow(heart),]


model_rf <- train(
  Target ~ ., 
  train.set,
  metric = "ROC",
  method = "ranger", 
  trControl = myControl
)

# plot(model_rf)

```


>>> Only first model

###Logistic Regression - Cross-Validated Models
```{r Logistic Regression}


cv_models_lr <- cv_data %>% 
  mutate(model = map(train, ~glm(formula = Target~., data = .x, family = "binomial")))


# Examine the first model and validate 
model <- cv_models_lr$model[[1]]
validate <- cv_models_lr$validate[[1]]



# Prepare binary vector of actual Heart Disease values in validate
validate_actual <- validate$Target == "Heart.Disease"

# Predict the probabilities for the observations in validate
validate_prob <- predict(model, validate, type = "response")


# Prepare binary vector of predicted Heart Disease values for validate
validate_predicted <- validate_prob > 0.5
# Compare the actual & predicted performance visually using a table

# table(validate_actual, validate_predicted)



ap.list <- matrix(nrow = 5, ncol = 2)

for(i in 1:5){
  m <- cv_models_lr$model[[i]]
  v <- cv_models_lr$validate[[i]]
  
  v_actual <- v$Target == "Heart.Disease"
  v_prob <- predict(m, v, type = "response")

  v_predicted <- v_prob > 0.5


               print(table(v_actual, v_predicted))

  
  ap.list[i,1] = Metrics::accuracy(v_actual, v_predicted)
  ap.list[i,2] = Metrics::precision(v_actual, v_predicted)
  
            if (i == 5){
              ap = apply(ap.list, 2, mean)
              print("Mean Accuracy")
              print(ap[1])
              print("Mean Precision")
              print(ap[2])
              }
}

```
*Confusion matrix of all the logistic regression models*
Using a logistic regression model to predict heart disease, the metrics of interest will be accuracy and precision. We would like to know who does and does not have heart disease, as well as how correct that true classification is.


*Mean Recall of training models*
```{r}

cv_prep_lr <- cv_models_lr %>% 
  mutate(validate_actual = map(validate, ~.x$Target == "Heart.Disease"),
         validate_predicted = map2(.x = model, .y = validate, 
                                   ~predict(.x, .y, type = "response") > 0.5)
         )

# Validate recall for each cross validation fold
cv_perf_recall <- cv_prep_lr %>% 
  mutate(validate_recall = map2_dbl(validate_actual, validate_predicted, 
                                    ~recall(actual = .x, predicted = .y)))


# cv_perf_recall$validate_recall
mean(cv_perf_recall$validate_recall)
```






```{r eval=FALSE, include=FALSE}
model.fold <- train(
  Target ~ ., 
  heart,
  method="glm", family="binomial",
  trControl = trainControl(
    method = "cv", 
    number = 10,
    verboseIter = TRUE
  )
  
)

model.fold
```



####Glmnet Modeling
```{r}
# Custom tuning grid for RF-modeling
# tune.grid <- data.frame(
#   .mtry = 2:length(heart),
#   .splitrule = "variance",
#   .min.node.size = 5
# )


# Custom tuning grid for Lasso or Ridge regression
tune.grid <- expand.grid(
  alpha = 0:1,
  lambda = seq(0.0001, 1, length = 20)
)


# Glmnet places constraints on coeff to prevent overfitting, fits a glm via maximum likelihood

# Ridge (0) or Lasso (1)
model.glmnet <- train(
  Target ~., 
  heart,
  metric = "ROC",
  tuneGrid = tune.grid,
  method = "glmnet",
  trControl = myControl,
  preProcess = c("medianImpute", "center", "scale")
)


plot(model.glmnet)
model.glmnet
#max(model.glmnet[["results"]][["ROC"]])
plot(model.glmnet$finalModel)
```




###Stepwise Selection - Logistic Regression
```{r}
model.0 <- glm(Target ~ 1, data = heart, family ="binomial")
model.1 <- glm(Target ~ . -Slope, data = heart, family = "binomial")

 step(model.0 , scope = formula(model.1), direction="forward", k = 2)
# formula = Target ~ ChestPain + Thalassemia + MajorVessels + 
#    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
#    Cholestrol + RestingBloodPressure + RestingECG

model.heart <- glm(formula = Target ~ ChestPain + Thalassemia + MajorVessels + 
    Oldpeak + ExerciseIndusedAngina + Gender + MaxHeartRateAchivied + 
    Cholestrol + RestingBloodPressure + RestingECG, family = "binomial", 
    data = heart)

summary(model.heart)
```

```{r}


```


```{r eval=FALSE, include=FALSE}
heart.df<- as.data.frame(heart.c)
keep <- c(1,4,5,8,10)
heart.df <- heart.df[, keep]



# for (i in 1:5){
#   print(boxplot.stats(heart.df[,i])$out)
# }

for (i in 1:5){
   AID::boxcoxnc(heart.df[,i], lambda = seq(-5,5,0.01), lambda2 = 2)
   print(i)
}


```







